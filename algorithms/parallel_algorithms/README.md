# ðŸ”„ Algoritmos Paralelos

Este diretÃ³rio contÃ©m implementaÃ§Ãµes de algoritmos paralelos usando o modelo **fork-join**, seguindo os princÃ­pios de **work/span analysis** para anÃ¡lise de performance.

## ðŸ“š ConteÃºdo

### ðŸ”¢ Fibonacci Paralelo (`fibonacci_parallel.py`)
- **P-FIB**: CÃ¡lculo recursivo de nÃºmeros de Fibonacci usando spawn/sync
- **AnÃ¡lise**: Work = Î˜(Ï†â¿), Span = Î˜(n), Parallelism = Î˜(Ï†â¿/n)
- **CaracterÃ­stica**: Demonstra paralelismo exponencial

### ðŸ”¢ MultiplicaÃ§Ã£o Matriz-Vetor (`matrix_vector_multiply.py`)
- **P-MAT-VEC**: MultiplicaÃ§Ã£o paralela de matriz nÃ—n por vetor n
- **AnÃ¡lise**: Work = Î˜(nÂ²), Span = Î˜(n), Parallelism = Î˜(n)
- **CaracterÃ­stica**: Paraleliza apenas o loop externo para evitar races

## ðŸŽ¯ Modelo Fork-Join

### ðŸ“¤ Palavras-Chave
- **spawn**: Executa subrotina em paralelo
- **sync**: Sincroniza threads spawnadas
- **parallel for**: Loop com iteraÃ§Ãµes paralelas

### ðŸ“Š MÃ©tricas de Performance
- **Work (Tâ‚)**: Tempo total em 1 processador
- **Span (Tâ‚)**: Tempo com âˆž processadores (caminho crÃ­tico)
- **Parallelism**: Tâ‚/Tâ‚ (razÃ£o work/span)

## ðŸ§ª ExecuÃ§Ã£o dos Testes

```bash
# Executar todos os testes
pytest algorithms/parallel_algorithms/

# Teste especÃ­fico
pytest algorithms/parallel_algorithms/test_fibonacci_parallel.py
pytest algorithms/parallel_algorithms/test_matrix_vector_multiply.py
```

## ðŸ“– DocumentaÃ§Ã£o TeÃ³rica

### ðŸ“š Notas de Estudo
- `notes/04. Algoritmos Paralelos/01. Fundamentos/01. Modelo Fork-Join.md`
- `notes/04. Algoritmos Paralelos/02. MultiplicaÃ§Ã£o de Matrizes/01. MultiplicaÃ§Ã£o Matriz-Vetor.md`
- `notes/04. Algoritmos Paralelos/02. MultiplicaÃ§Ã£o de Matrizes/02. MultiplicaÃ§Ã£o Recursiva.md`
- `notes/04. Algoritmos Paralelos/03. Merge Sort Paralelo/01. Algoritmo P-MERGE.md`
- `notes/04. Algoritmos Paralelos/04. Race Conditions/01. Determinacy Races.md`
- `notes/04. Algoritmos Paralelos/05. Estudo de Caso/01. LiÃ§Ã£o do Xadrez.md`

## âš ï¸ Race Conditions

### ðŸ Exemplos de Races
```python
# âŒ INCORRETO - Race condition
parallel for i = 1 to n:
    parallel for j = 1 to n:
        y[i] = y[i] + A[i][j] * x[j]  # MÃºltiplas threads escrevem em y[i]
```

### âœ… CÃ³digo DeterminÃ­stico
```python
# âœ… CORRETO - Sem races
parallel for i = 1 to n:
    for j = 1 to n:
        y[i] = y[i] + A[i][j] * x[j]  # Cada thread tem seu prÃ³prio i
```

## ðŸŽ® ImplementaÃ§Ã£o PrÃ¡tica

### ðŸ”§ LimitaÃ§Ãµes Atuais
- **ImplementaÃ§Ã£o Serial**: Por enquanto, as funÃ§Ãµes usam implementaÃ§Ã£o serial
- **TODO**: Implementar spawn/sync reais usando threading ou multiprocessing
- **Foco**: AnÃ¡lise teÃ³rica e estrutura dos algoritmos

### ðŸš€ PrÃ³ximos Passos
1. Implementar spawn/sync usando `concurrent.futures`
2. Adicionar merge sort paralelo (P-MERGE)
3. Implementar multiplicaÃ§Ã£o recursiva de matrizes
4. Adicionar algoritmos de reduÃ§Ã£o e scan

## ðŸ“ˆ AnÃ¡lise de Performance

### ðŸ” Lei do Work e Span
```
Tâ‚š â‰¥ max(Tâ‚/P, Tâ‚)
```

### ðŸŽ¯ Speedup MÃ¡ximo
- **Linear Speedup**: Tâ‚/Tâ‚š = P (speedup perfeito)
- **Limite**: Tâ‚/Tâ‚š â‰¤ Tâ‚/Tâ‚ (parallelism)

### ðŸ“Š Slackness
- **Slackness > 1**: Boa escalabilidade
- **Slackness < 1**: Span domina, speedup limitado

## ðŸŽ¯ LiÃ§Ãµes Aprendidas

### âœ… Boas PrÃ¡ticas
- **Identificar independÃªncia**: Paralelizar apenas operaÃ§Ãµes independentes
- **Evitar races**: Cada saÃ­da modificada por uma thread
- **AnÃ¡lise work/span**: Sempre analisar antes de implementar

### âŒ Armadilhas
- **Paralelizar loops aninhados**: Pode criar races inesperadas
- **Ignorar span**: Focar apenas em reduzir work
- **Over-parallelization**: Overhead pode dominar benefÃ­cio 