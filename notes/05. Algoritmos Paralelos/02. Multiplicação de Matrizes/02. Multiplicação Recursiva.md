# ğŸ”„ MultiplicaÃ§Ã£o Recursiva de Matrizes

## ğŸ¯ Problema
Multiplicar duas matrizes nÃ—n **C = C + A Ã— B** usando divisÃ£o e conquista paralela, evitando matrizes temporÃ¡rias para otimizar uso de memÃ³ria.

## ğŸ”§ EstratÃ©gia Divide-and-Conquer

### ğŸ“ DivisÃ£o em Submatrizes
```
A = [Aâ‚â‚  Aâ‚â‚‚]    B = [Bâ‚â‚  Bâ‚â‚‚]    C = [Câ‚â‚  Câ‚â‚‚]
    [Aâ‚‚â‚  Aâ‚‚â‚‚]        [Bâ‚‚â‚  Bâ‚‚â‚‚]        [Câ‚‚â‚  Câ‚‚â‚‚]
```

### ğŸ§® FÃ³rmulas de MultiplicaÃ§Ã£o
```
Câ‚â‚ = Câ‚â‚ + Aâ‚â‚Ã—Bâ‚â‚ + Aâ‚â‚‚Ã—Bâ‚‚â‚
Câ‚â‚‚ = Câ‚â‚‚ + Aâ‚â‚Ã—Bâ‚â‚‚ + Aâ‚â‚‚Ã—Bâ‚‚â‚‚  
Câ‚‚â‚ = Câ‚‚â‚ + Aâ‚‚â‚Ã—Bâ‚â‚ + Aâ‚‚â‚‚Ã—Bâ‚‚â‚
Câ‚‚â‚‚ = Câ‚‚â‚‚ + Aâ‚‚â‚Ã—Bâ‚â‚‚ + Aâ‚‚â‚‚Ã—Bâ‚‚â‚‚
```

## ğŸ”„ Algoritmo Paralelo

### ğŸ“ P-MATRIX-MULTIPLY-RECURSIVE
```python
def P-MATRIX-MULTIPLY-RECURSIVE(A, B, C, n):
    if n == 1:
        C[1][1] = C[1][1] + A[1][1] * B[1][1]
        return
    
    # Particiona matrizes em submatrizes n/2 Ã— n/2
    partition A, B, C into submatrices
    
    # Primeiro termo de cada Cáµ¢â±¼ (sem matriz temporÃ¡ria)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚â‚, Bâ‚â‚, Câ‚â‚, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚â‚, Bâ‚â‚‚, Câ‚â‚‚, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚‚â‚, Bâ‚â‚, Câ‚‚â‚, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚‚â‚, Bâ‚â‚‚, Câ‚‚â‚‚, n/2)
    sync
    
    # Segundo termo de cada Cáµ¢â±¼ (sem matriz temporÃ¡ria)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚â‚‚, Bâ‚‚â‚, Câ‚â‚, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚â‚‚, Bâ‚‚â‚‚, Câ‚â‚‚, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚‚â‚‚, Bâ‚‚â‚, Câ‚‚â‚, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚‚â‚‚, Bâ‚‚â‚‚, Câ‚‚â‚‚, n/2)
    sync
```

## ğŸ“Š AnÃ¡lise de Performance

### ğŸ” Work Analysis
```
Mâ‚(n) = 8Mâ‚(n/2) + O(1)
       = O(nÂ³)  # Mesmo que algoritmo serial
```

### â±ï¸ Span Analysis
```
Mâ‚(n) = Mâ‚(n/2) + O(log n)
       = O(logÂ² n)  # RecursÃ£o + overhead de loops
```

### ğŸš€ Parallelism
```
Parallelism = Mâ‚(n)/Mâ‚(n) = O(nÂ³/logÂ² n)
```

## âš ï¸ VersÃ£o com Matriz TemporÃ¡ria

### ğŸ“ P-MATRIX-MULTIPLY-WITH-TEMP
```python
def P-MATRIX-MULTIPLY-WITH-TEMP(A, B, C, n):
    if n == 1:
        C[1][1] = C[1][1] + A[1][1] * B[1][1]
        return
    
    let D be a new nÃ—n matrix  # âŒ Matriz temporÃ¡ria
    parallel for i = 1 to n:
        parallel for j = 1 to n:
            D[i][j] = 0
    
    # Primeiro termo: C = C + Aâ‚Ã—Bâ‚
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚â‚, Bâ‚â‚, Câ‚â‚, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚â‚, Bâ‚â‚‚, Câ‚â‚‚, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚‚â‚, Bâ‚â‚, Câ‚‚â‚, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚‚â‚, Bâ‚â‚‚, Câ‚‚â‚‚, n/2)
    sync
    
    # Segundo termo: D = Aâ‚‚Ã—Bâ‚‚
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚â‚‚, Bâ‚‚â‚, Dâ‚â‚, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚â‚‚, Bâ‚‚â‚‚, Dâ‚â‚‚, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚‚â‚‚, Bâ‚‚â‚, Dâ‚‚â‚, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(Aâ‚‚â‚‚, Bâ‚‚â‚‚, Dâ‚‚â‚‚, n/2)
    sync
    
    # C = C + D
    parallel for i = 1 to n:
        parallel for j = 1 to n:
            C[i][j] = C[i][j] + D[i][j]
```

## âš–ï¸ ComparaÃ§Ã£o das Abordagens

| Aspecto | Sem Temp | Com Temp |
|---------|----------|----------|
| **MemÃ³ria** | ğŸŸ¢ O(nÂ²) | ğŸ”´ O(nÂ²) extra |
| **Work** | ğŸŸ¢ O(nÂ³) | ğŸŸ¢ O(nÂ³) |
| **Span** | ğŸŸ¢ O(logÂ² n) | ğŸŸ¢ O(logÂ² n) |
| **Parallelism** | ğŸŸ¢ O(nÂ³/logÂ² n) | ğŸŸ¢ O(nÂ³/logÂ² n) |
| **Complexidade** | ğŸ”´ Mais complexo | ğŸŸ¢ Mais simples |

## ğŸ¯ OtimizaÃ§Ãµes

### ğŸ“ˆ Coarsening
```python
def P-MATRIX-MULTIPLY-COARSE(A, B, C, n, threshold):
    if n <= threshold:
        # Usar algoritmo serial otimizado
        SERIAL-MATRIX-MULTIPLY(A, B, C, n)
        return
    # ... resto do algoritmo recursivo
```

### ğŸ”„ Cache-Oblivious
- **Recursive blocking**: Adapta-se automaticamente ao cache
- **Memory hierarchy**: Funciona bem em mÃºltiplos nÃ­veis
- **Cache misses**: Minimizados pela localidade

## ğŸ§® ParalelizaÃ§Ã£o do MÃ©todo de Strassen

### ğŸ“ P-STRASSEN
```python
def P-STRASSEN(A, B, C, n):
    if n == 1:
        C[1][1] = A[1][1] * B[1][1]
        return
    
    # Criar matrizes Sâ‚...Sâ‚â‚€ e Pâ‚...Pâ‚‡
    create Sâ‚...Sâ‚â‚€, Pâ‚...Pâ‚‡  # O(nÂ²) work, O(log n) span
    
    # Calcular 7 produtos em paralelo
    spawn P-STRASSEN(Sâ‚, Sâ‚‚, Pâ‚, n/2)   # Pâ‚ = Sâ‚ Ã— Sâ‚‚
    spawn P-STRASSEN(Sâ‚ƒ, Sâ‚„, Pâ‚‚, n/2)   # Pâ‚‚ = Sâ‚ƒ Ã— Sâ‚„
    # ... mais 5 spawns
    sync
    
    # Calcular Câ‚â‚, Câ‚â‚‚, Câ‚‚â‚, Câ‚‚â‚‚ em paralelo
    parallel for i = 1 to n/2:
        parallel for j = 1 to n/2:
            C[i][j] = Pâ‚[i][j] + Pâ‚‚[i][j] - Pâ‚„[i][j] + Pâ‚†[i][j]
```

### ğŸ“Š AnÃ¡lise Strassen
- **Work**: Tâ‚(n) = O(n^logâ‚‚7) â‰ˆ O(n^2.81)
- **Span**: Tâ‚(n) = O(logÂ² n)
- **Parallelism**: O(n^logâ‚‚7/logÂ² n)

## ğŸ¯ LiÃ§Ãµes Aprendidas

### âœ… Boas PrÃ¡ticas
- **Evitar matrizes temporÃ¡rias**: Economiza memÃ³ria
- **SincronizaÃ§Ã£o cuidadosa**: Evita races
- **Coarsening**: Reduz overhead para matrizes pequenas

### âŒ Armadilhas
- **Complexidade aumentada**: Mais difÃ­cil de implementar
- **Overhead de sincronizaÃ§Ã£o**: Pode dominar para matrizes pequenas
- **Cache misses**: PadrÃ£o de acesso menos previsÃ­vel 