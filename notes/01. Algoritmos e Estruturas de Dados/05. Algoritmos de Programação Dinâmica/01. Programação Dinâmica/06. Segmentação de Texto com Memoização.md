# 🧠 Segmentação de Texto com Memoização

## 🎯 Visão Geral

O problema de **Segmentação de Texto (Word Break)** consiste em determinar se uma string sem espaços pode ser segmentada em uma sequência de palavras válidas usando um dicionário. A transição de backtracking exponencial O(2ⁿ) para programação dinâmica O(n²) demonstra a essência da PD.

## 📊 Definição do Problema

### 🎯 Entrada
- **String S**: Texto sem espaços de comprimento n
- **Dicionário D**: Conjunto de palavras válidas

### 🎯 Saída
- **Segmentação válida**: Lista [w₁, w₂, ..., wₖ] onde S = w₁ + w₂ + ... + wₖ
- **None**: Se não existir segmentação válida

### 📝 Exemplo
```
Entrada: S = "ilikegfg", D = {"i", "like", "gfg"}
Saída: ["i", "like", "gfg"]
```

## 🔄 Estratégias de Implementação

### 1️⃣ wordbreak_memo (Lilian Weng) ⭐
```python
def wordbreak_memo(text: str, dictionary: Set[str]) -> Optional[List[str]]:
    """
    Implementação direta da solução recursiva com dicionário para memoização.
    Baseada em: https://github.com/lilianweng/LeetcodePython/blob/master/word_break.py
    """
    memo = {}
    
    def can_break(s: str) -> Optional[List[str]]:
        if s in memo:
            return memo[s]
        
        if s == "":
            return []
        
        for i in range(1, len(s) + 1):
            prefix = s[:i]
            if prefix in dictionary:
                suffix_result = can_break(s[i:])
                if suffix_result is not None:
                    result = [prefix] + suffix_result
                    memo[s] = result
                    return result
        
        memo[s] = None
        return None
    
    return can_break(text)
```

### 2️⃣ HashMap Approach (Tutorial Horizon) ⭐
```python
def wordbreak_hashmap(text: str, dictionary: Set[str]) -> Optional[List[str]]:
    """
    Usa HashMap para armazenar resultados de substrings já processadas.
    Baseada em: https://tutorialhorizon.com/algorithms/the-word-break-problem/
    """
    memo = {}
    
    def can_segment(start: int) -> Optional[List[str]]:
        if start in memo:
            return memo[start]
        
        if start == len(text):
            return []
        
        for end in range(start + 1, len(text) + 1):
            word = text[start:end]
            if word in dictionary:
                remaining = can_segment(end)
                if remaining is not None:
                    result = [word] + remaining
                    memo[start] = result
                    return result
        
        memo[start] = None
        return None
    
    return can_segment(0)
```

### 3️⃣ Subproblemas Sobrepostos (GeeksforGeeks) ⭐
```python
def wordbreak_subproblems(text: str, dictionary: Set[str]) -> bool:
    """
    Análise de subproblemas sobrepostos com foco em complexidade.
    Baseada em: https://www.geeksforgeeks.org/dsa/word-break-problem-dp-32/
    """
    n = len(text)
    dp = [False] * (n + 1)
    dp[0] = True  # String vazia é sempre segmentável
    
    for i in range(1, n + 1):
        for j in range(i):
            if dp[j] and text[j:i] in dictionary:
                dp[i] = True
                break
    
    return dp[n]
```

## 🧠 Análise de Subproblemas

### 📍 Estado do Subproblema
- **Definição**: `dp[i]` = "O sufixo text[i..n] pode ser segmentado?"
- **Estados possíveis**: n (um para cada posição inicial)
- **Sobreposição**: Múltiplos caminhos chegam ao mesmo estado

### 🔗 Estrutura Ótima
Se `text[i..j]` é palavra válida e `text[j..n]` pode ser segmentado,
então `text[i..n]` pode ser segmentado.

**Fórmula**: `dp[i] = OR(dp[j] AND is_word(text[i..j]))` para todo j > i

## ⚡ Melhoria de Performance

| Abordagem | Complexidade | Vantagem | Desvantagem |
|-----------|-------------|----------|-------------|
| **Backtracking** | O(2ⁿ) | 🚀 Simples | ❌ Exponencial |
| **wordbreak_memo** | O(n²) | 🛡️ String como chave | 💾 Cache |
| **HashMap Approach** | O(n²) | ⚡ Índice como chave | 📊 Memória |
| **Subproblemas** | O(n²) | 🔄 Bottom-up | 📈 Array |

## 🎯 Implementações Disponíveis

### ✅ Implementadas
- `wordbreak_memo()` - Solução recursiva com string como chave
- `wordbreak_hashmap()` - Solução recursiva com índice como chave  
- `wordbreak_subproblems()` - Abordagem bottom-up com array

### 🔄 Para Implementar
- `text_segmentation_optimized_memoization()` - Ordenação decrescente
- `text_segmentation_with_trie()` - Otimização com Trie
- `text_segmentation_with_bfs()` - Busca em largura
- `text_segmentation_with_dfs()` - Busca em profundidade
- `text_segmentation_all_solutions()` - Todas as segmentações
- `text_segmentation_count_solutions()` - Contagem de soluções
- `text_segmentation_with_constraints()` - Restrições adicionais

## 📊 Casos de Teste

### ✅ Casos Básicos
```python
("ilike", {"i", "like", "gfg"}, ["i", "like"])
("ilikegfg", {"i", "like", "gfg"}, ["i", "like", "gfg"])
("ilikemangoes", {"i", "like", "gfg"}, None)
```

### 🔄 Casos com Múltiplas Soluções
```python
("catsanddog", {"cat", "cats", "and", "sand", "dog"}, ["cat", "sand", "dog"])
```

### ⚠️ Casos Extremos
```python
("", {"a", "b"}, [])
("a", {"a"}, ["a"])
("a", {"b"}, None)
```

## 🚀 Benchmark de Performance

| Tamanho | Backtracking | wordbreak_memo | HashMap | Subproblemas |
|---------|-------------|----------------|---------|--------------|
| 10      | 0.0016s     | 0.0000s        | 0.0000s | 0.0000s      |
| 20      | 0.0000s     | 0.0000s        | 0.0000s | 0.0000s      |
| 30      | Muito lento | 0.0000s        | 0.0000s | 0.0000s      |
| 40      | Muito lento | 0.0000s        | 0.0000s | 0.0000s      |
| 50      | Muito lento | 0.0000s        | 0.0021s | 0.0015s      |

## 🔗 Vínculos Conceituais

### 📚 Referências Teóricas
- **Erickson, "Algorithms"**: Capítulo 3, Seção 3.3, "Interpunctio Verborum Redux"
- **Lilian Weng**: [wordbreak_memo](https://github.com/lilianweng/LeetcodePython/blob/master/word_break.py)
- **Tutorial Horizon**: [HashMap Approach](https://tutorialhorizon.com/algorithms/the-word-break-problem/)
- **GeeksforGeeks**: [Subproblemas Sobrepostos](https://www.geeksforgeeks.org/dsa/word-break-problem-dp-32/)

### 🧠 Conceitos Demonstrados
1. **Transição de Backtracking para PD**: O(2ⁿ) → O(n²)
2. **Estado do Subproblema**: Índice inicial do sufixo
3. **Subproblemas Sobrepostos**: Múltiplos caminhos para o mesmo estado
4. **Estrutura Ótima**: Decomposição em subproblemas menores
5. **Técnicas de Otimização**: Ordenação de tentativas, cache eficiente

## 💡 Insights Teóricos

### 🔄 Filosofia da PD
- **"PD é Recursão Inteligente"**: Otimização de algoritmos recursivos
- **Transição Suave**: Mantém estrutura lógica da recursão original
- **Cache Inteligente**: Adiciona cache para evitar recálculos
- **Identificação de Estado**: Representação única de subproblemas

### ⚡ Abordagens Fundamentais
- **Memoização (Top-Down)**: Cache de resultados durante recursão
- **Tabelação (Bottom-Up)**: Construção iterativa da tabela de soluções
- **Subestrutura Ótima**: Propriedade que permite decomposição
- **Sobreposição de Subproblemas**: Justificativa para cache

## 🎯 Aplicações Práticas

### 🔧 Cenários Reais
- **Processamento de Texto**: Segmentação de texto sem espaços
- **Compiladores**: Análise léxica e parsing
- **IA e NLP**: Processamento de linguagem natural
- **Sistemas de Busca**: Indexação e recuperação de texto

### 🚀 Benefícios da Implementação
- **Performance**: Reduz complexidade exponencial para quadrática
- **Escalabilidade**: Viável para strings de tamanho moderado
- **Flexibilidade**: Suporta diferentes estratégias de otimização
- **Educacional**: Demonstra princípios fundamentais da PD

## 🎯 Próximos Passos

### 🔄 Implementações Pendentes
1. **Memoização Otimizada**: Ordenação decrescente de tentativas
2. **Solução com Trie**: Otimização de busca de palavras
3. **BFS/DFS**: Abordagens alternativas de busca
4. **Todas as Soluções**: Encontrar múltiplas segmentações
5. **Contagem de Soluções**: Programação dinâmica para contagem
6. **Restrições**: Adicionar limitações específicas

## 🧠 Análise de Especialista

### 📊 Estado do Subproblema
- **Definição Única**: `dp[i]` = "O sufixo text[i..n] pode ser segmentado?"
- **Estados Limitados**: Apenas n sufixos possíveis
- **Cache Eficiente**: Array 1D ou dicionário suficiente

### ⚡ Complexidade Justificada
- **Tempo O(n²)**: Para cada estado i, loop interno itera até n-i vezes
- **IsWord O(k)**: Cada verificação de palavra leva tempo proporcional ao comprimento
- **Total O(n²)**: Soma das iterações para todos os estados

### 🔄 Subproblemas Sobrepostos
- **Múltiplos Caminhos**: Diferentes prefixos levam ao mesmo sufixo
- **Recálculos Evitados**: Cache elimina trabalho redundante
- **Eficiência Garantida**: Cada subproblema resolvido apenas uma vez

Este módulo demonstra efetivamente como a memoização pode transformar um algoritmo exponencial em um algoritmo polinomial, seguindo exatamente os princípios descritos por Erickson em "Algorithms". 