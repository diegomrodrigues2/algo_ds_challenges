# Optimal Binary Search Tree (OBST) - Versão Backtracking

## Visão Geral do Problema

O problema da Árvore de Busca Binária Ótima (OBST) é um problema clássico de algoritmos que consiste em construir uma árvore de busca binária que minimize o custo total de todas as buscas, dado um array ordenado de chaves e suas frequências de busca.

**Definição Formal:**
Dado um array ordenado de chaves `keys[0..n-1]` e um array de frequências `freq[0..n-1]`, onde `freq[i]` é o número de buscas pela chave `keys[i]`, construir uma árvore de busca binária que minimize o custo total de todas as buscas. O custo de um nó é seu nível na árvore multiplicado por sua frequência.

**Vínculo Conceitual:** Erickson, "Algorithms", Capítulo 2, Seção 2.8, "Optimal Binary Search Trees"

## Formulação de Erickson

Erickson apresenta a formulação recursiva OptCost(i, k):

```
OptCost(i, k) = min(OptCost(i, r-1) + OptCost(r+1, k) + fsum) para r em [i, k]
```

Onde:
- `OptCost(i, k)` é o custo mínimo da árvore ótima para as chaves `keys[i..k]`
- `fsum` é a soma das frequências `freq[i..k]`
- Para cada possível raiz `r` no intervalo `[i, k]`, calculamos o custo e escolhemos o mínimo

## Estratégia de Backtracking

### Árvore de Decisão

Para cada intervalo `[i, k]`, a recursão testa todas as possíveis raízes:

```
                    OptCost(i, k)
                    /            \
        OptCost(i, r-1)    OptCost(r+1, k)
        (left subtree)     (right subtree)
```

### Pseudocódigo

```python
def OptCost(i, k):
    if i > k:
        return 0  # No nodes in this range
    if i == k:
        return freq[i]  # Single node
    
    # Get sum of frequencies for this range
    fsum = sum(freq[i..k])
    
    # Try each key as root and find minimum cost
    min_cost = infinity
    for r in range(i, k + 1):
        cost = OptCost(i, r-1) + OptCost(r+1, k)
        if cost < min_cost:
            min_cost = cost
    
    return min_cost + fsum

def OBST(keys, freq):
    return OptCost(0, len(keys) - 1)
```

## Análise de Complexidade

### Tempo

**Sem Memoização:**
- Relação de recorrência: T(n) = Σ T(r-1) × T(n-r) para r de 1 a n
- Solução: T(n) = O(n × 2^n)
- Cada intervalo testa todas as possíveis raízes

**Com Memoização:**
- Estados únicos: O(n²) - (i, k) pairs
- Tempo por estado: O(n) - soma de frequências
- Complexidade total: O(n³)

### Espaço

**Sem Memoização:**
- Profundidade da recursão: O(n)
- Espaço total: O(n)

**Com Memoização:**
- Tabela de memoização: O(n²)
- Pilha de recursão: O(n)
- Espaço total: O(n²)

## Implementações Especializadas

### 1. Backtracking Básico

```python
def obst_backtracking(keys, freq):
    def sum_freq(i, j):
        return sum(freq[i:j+1])
    
    def opt_cost(i, j):
        if i > j:
            return 0
        if i == j:
            return freq[i]
        
        fsum = sum_freq(i, j)
        min_cost = float('inf')
        
        for r in range(i, j + 1):
            cost = opt_cost(i, r - 1) + opt_cost(r + 1, j)
            if cost < min_cost:
                min_cost = cost
        
        return min_cost + fsum
    
    return opt_cost(0, len(keys) - 1)
```

### 2. Backtracking com Memoização

```python
def obst_backtracking_with_memoization(keys, freq):
    memo = {}
    
    def sum_freq(i, j):
        return sum(freq[i:j+1])
    
    def opt_cost(i, j):
        if i > j:
            return 0
        if i == j:
            return freq[i]
        
        state = (i, j)
        if state in memo:
            return memo[state]
        
        fsum = sum_freq(i, j)
        min_cost = float('inf')
        
        for r in range(i, j + 1):
            cost = opt_cost(i, r - 1) + opt_cost(r + 1, j)
            if cost < min_cost:
                min_cost = cost
        
        memo[state] = min_cost + fsum
        return memo[state]
    
    return opt_cost(0, len(keys) - 1)
```

### 3. Encontrar Estrutura Ótima

```python
def obst_backtracking_with_structure(keys, freq):
    memo = {}
    root_structure = {}
    
    def sum_freq(i, j):
        return sum(freq[i:j+1])
    
    def opt_cost(i, j):
        if i > j:
            return 0
        if i == j:
            return freq[i]
        
        state = (i, j)
        if state in memo:
            return memo[state]
        
        fsum = sum_freq(i, j)
        min_cost = float('inf')
        best_root = i
        
        for r in range(i, j + 1):
            cost = opt_cost(i, r - 1) + opt_cost(r + 1, j)
            if cost < min_cost:
                min_cost = cost
                best_root = r
        
        memo[state] = min_cost + fsum
        root_structure[state] = best_root
        return memo[state]
    
    result = opt_cost(0, len(keys) - 1)
    return (result, root_structure)
```

### 4. Contar Estruturas Ótimas

```python
def obst_backtracking_count_structures(keys, freq):
    memo = {}
    count_memo = {}
    
    def sum_freq(i, j):
        return sum(freq[i:j+1])
    
    def opt_cost(i, j):
        # ... (same as memoized version)
    
    def count_structures(i, j):
        if i > j:
            return 1
        if i == j:
            return 1
        
        state = (i, j)
        if state in count_memo:
            return count_memo[state]
        
        optimal_cost = opt_cost(i, j)
        fsum = sum_freq(i, j)
        
        count = 0
        for r in range(i, j + 1):
            cost = opt_cost(i, r - 1) + opt_cost(r + 1, j)
            if cost + fsum == optimal_cost:
                left_count = count_structures(i, r - 1)
                right_count = count_structures(r + 1, j)
                count += left_count * right_count
        
        count_memo[state] = count
        return count
    
    min_cost = opt_cost(0, len(keys) - 1)
    structure_count = count_structures(0, len(keys) - 1)
    
    return (min_cost, structure_count)
```

### 5. Backtracking Otimizado

```python
def obst_backtracking_optimized(keys, freq):
    memo = {}
    
    def sum_freq(i, j):
        return sum(freq[i:j+1])
    
    def opt_cost(i, j):
        if i > j:
            return 0
        if i == j:
            return freq[i]
        
        state = (i, j)
        if state in memo:
            return memo[state]
        
        fsum = sum_freq(i, j)
        min_cost = float('inf')
        
        # Optimization: Try middle elements first
        mid = (i + j) // 2
        for offset in range(j - i + 1):
            r = mid + offset if mid + offset <= j else i + (mid + offset - j - 1)
            if i <= r <= j:
                cost = opt_cost(i, r - 1) + opt_cost(r + 1, j)
                if cost < min_cost:
                    min_cost = cost
        
        memo[state] = min_cost + fsum
        return memo[state]
    
    return opt_cost(0, len(keys) - 1)
```

## Otimizações Implementadas

### 1. Memoização
- **Objetivo**: Evitar recálculo de subproblemas
- **Implementação**: Tabela hash para estados (i, j)
- **Benefício**: Reduz complexidade de O(n × 2^n) para O(n³)

### 2. Ordenação de Tentativas
- **Objetivo**: Tentar raízes mais promissoras primeiro
- **Implementação**: Começar pelo elemento do meio
- **Benefício**: Pode encontrar a solução ótima mais rapidamente

### 3. Formulação de Erickson
- **Objetivo**: Implementação direta da formulação teórica
- **Implementação**: OptCost(i, k) com parâmetros explícitos
- **Benefício**: Clareza conceitual e facilita otimizações

## Análise Detalhada da Complexidade

### Relação de Recorrência

Para a formulação de Erickson:
```
T(n) = Σ T(r-1) × T(n-r) para r de 1 a n
```

### Solução da Recorrência

**Método da Árvore de Recursão:**
```
Nível 0: 1 chamada
Nível 1: n chamadas
Nível 2: n² chamadas
...
Nível n: n^n chamadas
```

Total: O(n × 2^n) - exponencial

### Com Memoização

**Estados únicos:**
- i: 0 a n-1 (n valores)
- j: 0 a n-1 (n valores)
- Total de estados: O(n²)

**Tempo por estado:** O(n) - soma de frequências
**Complexidade total:** O(n³)

## Aplicações Práticas

### 1. Compiladores
- **Otimização de Tabelas de Símbolos**: Estruturas de dados eficientes para símbolos
- **Análise Léxica**: Otimização de reconhecimento de tokens
- **Análise Sintática**: Árvores de parsing otimizadas

### 2. Sistemas de Banco de Dados
- **Índices Otimizados**: Estruturas de busca eficientes
- **Query Optimization**: Otimização de consultas
- **Index Selection**: Seleção de índices ótimos

### 3. Processamento de Linguagem Natural
- **Dicionários Otimizados**: Estruturas de busca para vocabulário
- **Spell Checking**: Correção ortográfica eficiente
- **Autocomplete**: Sugestões de texto otimizadas

### 4. Sistemas de Busca
- **Estruturas de Dados Otimizadas**: Árvores de busca eficientes
- **Indexação de Texto**: Índices invertidos otimizados
- **Ranking Algorithms**: Algoritmos de ranking otimizados

### 5. Compressão de Dados
- **Árvores Huffman Otimizadas**: Codificação de comprimento variável
- **Árvores de Prefixo**: Estruturas de dados para compressão
- **Dicionários de Compressão**: Tabelas de substituição otimizadas

## Insights Teóricos

### 1. Sobreposição de Subproblemas
- Muitos subproblemas são resolvidos múltiplas vezes
- Isso torna o problema ideal para memoização
- A memoização reduz drasticamente a complexidade

### 2. Teste de Todas as Raízes
- Cada intervalo testa todas as possíveis raízes
- Isso leva naturalmente à complexidade exponencial
- A estrutura é ideal para otimizações com memoização

### 3. Base para Programação Dinâmica
- O backtracking é a base para soluções de DP
- A formulação recursiva é natural para DP
- A otimização com memoização é o primeiro passo para DP

### 4. Formulação de Erickson
- OptCost(i, k) é intuitiva
- Facilita a implementação de otimizações
- Conecta diretamente com a teoria

### 5. Complexidade Exponencial
- Demonstra a necessidade de otimização
- Serve como exemplo de problema NP-difícil
- Ilustra a importância de algoritmos eficientes

## Limites Teóricos

### Complexidade
- **Sem otimização**: O(n × 2^n) - exponencial
- **Com memoização**: O(n³) - polinomial
- **Com DP tabular**: O(n³) - mas mais eficiente na prática

### Espaço de Soluções
- **Número de árvores possíveis**: O(4^n / n^(3/2)) - números de Catalan
- **Número de estruturas ótimas**: Pode ser exponencial
- **Custo mínimo**: O(n²) - soma de frequências

### Limites Práticos
- **Sem memoização**: Limitado a n ≈ 15-20
- **Com memoização**: Limitado a n ≈ 100-200
- **Com DP otimizado**: Limitado a n ≈ 1000-2000

## Comparação com Outras Abordagens

### 1. Programação Dinâmica Tabular
- **Complexidade**: O(n³)
- **Vantagem**: Mais eficiente para n grande
- **Desvantagem**: Menos intuitivo

### 2. Algoritmo de Knuth
- **Complexidade**: O(n²)
- **Vantagem**: Mais eficiente
- **Desvantagem**: Mais complexo de implementar

### 3. Algoritmos Aproximados
- **Complexidade**: O(n log n)
- **Vantagem**: Muito rápido
- **Desvantagem**: Pode não encontrar a solução ótima

## Variações do Problema

### 1. OBST com Pesos
- **Problema**: Chaves com pesos diferentes
- **Complexidade**: O(n³) com DP
- **Aplicação**: Sistemas com prioridades

### 2. OBST com Restrições
- **Problema**: OBST com restrições adicionais na estrutura
- **Complexidade**: Depende das restrições
- **Aplicação**: Sistemas com limitações de memória

### 3. OBST Aproximado
- **Problema**: Encontrar árvore próxima da ótima
- **Complexidade**: O(n log n)
- **Aplicação**: Sistemas com restrições de tempo

### 4. OBST Múltiplo
- **Problema**: Encontrar OBST para múltiplas árvores
- **Complexidade**: O(k × n³) para k árvores
- **Aplicação**: Sistemas distribuídos

### 5. OBST com Duplicatas
- **Problema**: Chaves podem ser repetidas
- **Complexidade**: O(n³)
- **Aplicação**: Sistemas com dados duplicados

## Conclusão

O problema OBST com backtracking demonstra:

1. **Estrutura Natural**: A formulação recursiva é intuitiva
2. **Necessidade de Otimização**: Complexidade exponencial requer otimizações
3. **Base para DP**: Backtracking é a base para soluções eficientes
4. **Aplicabilidade**: Problema relevante em múltiplas áreas
5. **Insights Teóricos**: Ilustra conceitos fundamentais de algoritmos

A implementação backtracking serve como:
- **Exemplo Educacional**: Demonstra conceitos de recursão e backtracking
- **Base para Otimização**: Ponto de partida para memoização e DP
- **Ferramenta Prática**: Útil para problemas de tamanho moderado
- **Referência Teórica**: Conecta com a formulação de Erickson 