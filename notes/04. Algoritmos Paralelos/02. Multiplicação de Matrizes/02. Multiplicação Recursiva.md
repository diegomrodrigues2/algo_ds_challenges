# 🔄 Multiplicação Recursiva de Matrizes

## 🎯 Problema
Multiplicar duas matrizes n×n **C = C + A × B** usando divisão e conquista paralela, evitando matrizes temporárias para otimizar uso de memória.

## 🔧 Estratégia Divide-and-Conquer

### 📐 Divisão em Submatrizes
```
A = [A₁₁  A₁₂]    B = [B₁₁  B₁₂]    C = [C₁₁  C₁₂]
    [A₂₁  A₂₂]        [B₂₁  B₂₂]        [C₂₁  C₂₂]
```

### 🧮 Fórmulas de Multiplicação
```
C₁₁ = C₁₁ + A₁₁×B₁₁ + A₁₂×B₂₁
C₁₂ = C₁₂ + A₁₁×B₁₂ + A₁₂×B₂₂  
C₂₁ = C₂₁ + A₂₁×B₁₁ + A₂₂×B₂₁
C₂₂ = C₂₂ + A₂₁×B₁₂ + A₂₂×B₂₂
```

## 🔄 Algoritmo Paralelo

### 📝 P-MATRIX-MULTIPLY-RECURSIVE
```python
def P-MATRIX-MULTIPLY-RECURSIVE(A, B, C, n):
    if n == 1:
        C[1][1] = C[1][1] + A[1][1] * B[1][1]
        return
    
    # Particiona matrizes em submatrizes n/2 × n/2
    partition A, B, C into submatrices
    
    # Primeiro termo de cada Cᵢⱼ (sem matriz temporária)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₁₁, B₁₁, C₁₁, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₁₁, B₁₂, C₁₂, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₂₁, B₁₁, C₂₁, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₂₁, B₁₂, C₂₂, n/2)
    sync
    
    # Segundo termo de cada Cᵢⱼ (sem matriz temporária)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₁₂, B₂₁, C₁₁, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₁₂, B₂₂, C₁₂, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₂₂, B₂₁, C₂₁, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₂₂, B₂₂, C₂₂, n/2)
    sync
```

## 📊 Análise de Performance

### 🔍 Work Analysis
```
M₁(n) = 8M₁(n/2) + O(1)
       = O(n³)  # Mesmo que algoritmo serial
```

### ⏱️ Span Analysis
```
M₁(n) = M₁(n/2) + O(log n)
       = O(log² n)  # Recursão + overhead de loops
```

### 🚀 Parallelism
```
Parallelism = M₁(n)/M₁(n) = O(n³/log² n)
```

## ⚠️ Versão com Matriz Temporária

### 📝 P-MATRIX-MULTIPLY-WITH-TEMP
```python
def P-MATRIX-MULTIPLY-WITH-TEMP(A, B, C, n):
    if n == 1:
        C[1][1] = C[1][1] + A[1][1] * B[1][1]
        return
    
    let D be a new n×n matrix  # ❌ Matriz temporária
    parallel for i = 1 to n:
        parallel for j = 1 to n:
            D[i][j] = 0
    
    # Primeiro termo: C = C + A₁×B₁
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₁₁, B₁₁, C₁₁, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₁₁, B₁₂, C₁₂, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₂₁, B₁₁, C₂₁, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₂₁, B₁₂, C₂₂, n/2)
    sync
    
    # Segundo termo: D = A₂×B₂
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₁₂, B₂₁, D₁₁, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₁₂, B₂₂, D₁₂, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₂₂, B₂₁, D₂₁, n/2)
    spawn P-MATRIX-MULTIPLY-RECURSIVE(A₂₂, B₂₂, D₂₂, n/2)
    sync
    
    # C = C + D
    parallel for i = 1 to n:
        parallel for j = 1 to n:
            C[i][j] = C[i][j] + D[i][j]
```

## ⚖️ Comparação das Abordagens

| Aspecto | Sem Temp | Com Temp |
|---------|----------|----------|
| **Memória** | 🟢 O(n²) | 🔴 O(n²) extra |
| **Work** | 🟢 O(n³) | 🟢 O(n³) |
| **Span** | 🟢 O(log² n) | 🟢 O(log² n) |
| **Parallelism** | 🟢 O(n³/log² n) | 🟢 O(n³/log² n) |
| **Complexidade** | 🔴 Mais complexo | 🟢 Mais simples |

## 🎯 Otimizações

### 📈 Coarsening
```python
def P-MATRIX-MULTIPLY-COARSE(A, B, C, n, threshold):
    if n <= threshold:
        # Usar algoritmo serial otimizado
        SERIAL-MATRIX-MULTIPLY(A, B, C, n)
        return
    # ... resto do algoritmo recursivo
```

### 🔄 Cache-Oblivious
- **Recursive blocking**: Adapta-se automaticamente ao cache
- **Memory hierarchy**: Funciona bem em múltiplos níveis
- **Cache misses**: Minimizados pela localidade

## 🧮 Paralelização do Método de Strassen

### 📝 P-STRASSEN
```python
def P-STRASSEN(A, B, C, n):
    if n == 1:
        C[1][1] = A[1][1] * B[1][1]
        return
    
    # Criar matrizes S₁...S₁₀ e P₁...P₇
    create S₁...S₁₀, P₁...P₇  # O(n²) work, O(log n) span
    
    # Calcular 7 produtos em paralelo
    spawn P-STRASSEN(S₁, S₂, P₁, n/2)   # P₁ = S₁ × S₂
    spawn P-STRASSEN(S₃, S₄, P₂, n/2)   # P₂ = S₃ × S₄
    # ... mais 5 spawns
    sync
    
    # Calcular C₁₁, C₁₂, C₂₁, C₂₂ em paralelo
    parallel for i = 1 to n/2:
        parallel for j = 1 to n/2:
            C[i][j] = P₁[i][j] + P₂[i][j] - P₄[i][j] + P₆[i][j]
```

### 📊 Análise Strassen
- **Work**: T₁(n) = O(n^log₂7) ≈ O(n^2.81)
- **Span**: T₁(n) = O(log² n)
- **Parallelism**: O(n^log₂7/log² n)

## 🎯 Lições Aprendidas

### ✅ Boas Práticas
- **Evitar matrizes temporárias**: Economiza memória
- **Sincronização cuidadosa**: Evita races
- **Coarsening**: Reduz overhead para matrizes pequenas

### ❌ Armadilhas
- **Complexidade aumentada**: Mais difícil de implementar
- **Overhead de sincronização**: Pode dominar para matrizes pequenas
- **Cache misses**: Padrão de acesso menos previsível 