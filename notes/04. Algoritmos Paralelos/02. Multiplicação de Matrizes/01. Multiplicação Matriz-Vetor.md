# 🔢 Multiplicação Matriz-Vetor Paralela

## 🎯 Problema
Calcular **y = Ax** onde A é uma matriz n×n e x é um vetor n-dimensional, usando paralelismo para acelerar o cálculo.

## 🔧 Algoritmo Básico

### 📝 P-MAT-VEC
```python
def P-MAT-VEC(A, x, y, n):
    parallel for i = 1 to n:           # Paraleliza linhas
        for j = 1 to n:                # Loop interno serial
            y[i] = y[i] + A[i][j] * x[j]
```

### 🎯 Estratégia
- **Loop externo paralelo**: Cada linha calculada independentemente
- **Loop interno serial**: Produto interno de cada linha
- **Sem races**: Cada y[i] modificado por apenas uma thread

## 📊 Análise de Performance

### 🔍 Work Analysis
- **Serial projection**: Θ(n²) - mesmo que algoritmo serial
- **Work**: T₁(n) = Θ(n²)
- **Overhead**: Recursive spawning não afeta assintoticamente

### ⏱️ Span Analysis
- **Loop control**: Θ(log n) para parallel for
- **Inner loop**: Θ(n) para cada iteração
- **Total span**: T₁(n) = Θ(log n) + Θ(n) = Θ(n)

### 🚀 Parallelism
```
Parallelism = T₁(n)/T₁(n) = Θ(n²)/Θ(n) = Θ(n)
```

## 🔄 Implementação com Recursive Spawning

### 📝 P-MAT-VEC-RECURSIVE
```python
def P-MAT-VEC-RECURSIVE(A, x, y, n, i, i₀):
    if i == i₀:                        # Base case: uma iteração
        for j = 1 to n:
            y[i] = y[i] + A[i][j] * x[j]
    else:
        mid = (i + i₀) // 2            # Divide ao meio
        spawn P-MAT-VEC-RECURSIVE(A, x, y, n, i, mid)
        P-MAT-VEC-RECURSIVE(A, x, y, n, mid + 1, i₀)
        sync
```

### 🌳 Árvore de Execução
- **Binary tree**: Cada nó divide o trabalho ao meio
- **Leaves**: Executam o loop serial
- **Internal nodes**: Apenas divisão e sincronização

## ⚠️ Versão Incorreta

### ❌ P-MAT-VEC-WRONG
```python
def P-MAT-VEC-WRONG(A, x, y, n):
    parallel for i = 1 to n:
        parallel for j = 1 to n:       # ❌ RACE CONDITION!
            y[i] = y[i] + A[i][j] * x[j]
```

### 🏁 Problema
- **Race condition**: Múltiplas threads escrevem em y[i]
- **Não-determinístico**: Resultado pode variar entre execuções
- **Incorreto**: Mesmo que span seja Θ(log n)

## 🎯 Otimizações

### 📈 Coarsening
```python
def P-MAT-VEC-COARSE(A, x, y, n, grain_size):
    parallel for i = 1 to n:
        for j = 1 to n:
            y[i] = y[i] + A[i][j] * x[j]
        # Processa múltiplas linhas por thread
```

### ⚖️ Trade-offs
| Aspecto | Granularidade Fina | Granularidade Grossa |
|---------|-------------------|---------------------|
| **Parallelism** | 🚀 Alta | 📉 Reduzida |
| **Overhead** | 📈 Alto | 📉 Baixo |
| **Load Balance** | ⚖️ Melhor | ⚖️ Pior |

## 🔍 Casos de Uso

### 📊 Matrizes Esparsas
- **Estrutura especial**: Aproveitar padrões de zeros
- **Compressed formats**: CSR, CSC para eficiência
- **Parallelism**: Ainda Θ(n) mas com menos work

### 🎯 Matrizes de Blocos
- **Block-wise**: Dividir em submatrizes
- **Cache-friendly**: Melhor localidade de dados
- **Hierarchical**: Paralelismo em múltiplos níveis

## 📈 Comparação de Performance

| Algoritmo | Work | Span | Parallelism |
|-----------|------|------|-------------|
| **Serial** | Θ(n²) | Θ(n²) | 1 |
| **P-MAT-VEC** | Θ(n²) | Θ(n) | Θ(n) |
| **P-MAT-VEC-WRONG** | Θ(n²) | Θ(log n) | Θ(n²/log n) |

## 🎯 Lições Aprendidas

### ✅ Boas Práticas
- **Identificar independência**: Linhas podem ser paralelas
- **Evitar races**: Cada saída modificada por uma thread
- **Balancear granularidade**: Overhead vs. parallelism

### ❌ Armadilhas
- **Paralelizar loops aninhados**: Pode criar races
- **Ignorar dependências**: Resultado incorreto
- **Over-parallelization**: Overhead domina benefício 